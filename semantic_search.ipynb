{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No sentence-transformers model found with name Supabase/gte-small. Creating a new one with MEAN pooling.\n",
      "/home/codespace/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8980]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "sentences = [\n",
    "    'The new movie is awesome',\n",
    "    'This recent movie is so good',\n",
    "]\n",
    "\n",
    "model = SentenceTransformer('Supabase/gte-small')\n",
    "embeddings = model.encode(sentences)\n",
    "print(cos_sim(embeddings[0], embeddings[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat sits outside \t\t The dog plays in the garden \t\t Score: 0.8200\n",
      "A man is playing guitar \t\t A woman watches TV \t\t Score: 0.7016\n",
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.9697\n"
     ]
    }
   ],
   "source": [
    "# Two lists of sentences\n",
    "sentences1 = [\n",
    "    \"The cat sits outside\",\n",
    "    \"A man is playing guitar\",\n",
    "    \"The new movie is awesome\",\n",
    "]\n",
    "\n",
    "sentences2 = [\n",
    "    \"The dog plays in the garden\",\n",
    "    \"A woman watches TV\",\n",
    "    \"The new movie is so great\",\n",
    "]\n",
    "\n",
    "# Compute embedding for both lists\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "# Compute cosine-similarities\n",
    "cosine_scores = cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "# Output the pairs with their score\n",
    "for i in range(len(sentences1)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(\n",
    "        sentences1[i], sentences2[i], cosine_scores[i][i]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: This framework generates embeddings for each input sentence\n",
      "Embedding: [-4.56867486e-01 -6.03742972e-02  2.77016293e-02 -1.49324358e-01\n",
      " -2.58532297e-02  3.99035186e-01 -1.55860446e-02  2.39103347e-01\n",
      "  9.95150059e-02  1.49657831e-01 -3.45252037e-01 -4.33488727e-01\n",
      "  6.84537292e-01  2.49792576e-01  3.92542243e-01  3.05619419e-01\n",
      " -2.38010868e-01  3.97296071e-01 -4.60435927e-01 -1.37540191e-01\n",
      "  5.90817511e-01 -2.84304410e-01  1.05978183e-01 -5.92266262e-01\n",
      " -1.59350604e-01  4.13091660e-01 -1.64931834e-01 -7.34144747e-02\n",
      " -3.01011682e-01 -1.89854681e+00  2.36648750e-02 -5.51726222e-01\n",
      "  7.99842536e-01 -4.33844179e-02 -2.60188371e-01 -1.74996138e-01\n",
      " -4.91537124e-01  4.09644157e-01 -1.80871084e-01  2.30171144e-01\n",
      "  2.36194789e-01  2.71462411e-01  2.17981972e-02 -6.09191358e-01\n",
      " -2.04824001e-01 -5.56083083e-01 -6.08014345e-01  7.76969464e-05\n",
      " -8.24697912e-02 -2.05188259e-01 -7.09770173e-02 -4.21118379e-01\n",
      " -9.76334363e-02  8.62644464e-02  2.12224185e-01  1.12527296e-01\n",
      "  2.59943545e-01  3.95329207e-01 -6.50232360e-02  5.24257720e-01\n",
      "  1.58541843e-01  4.68619496e-01 -1.60996580e+00  5.79657078e-01\n",
      "  1.82124764e-01  2.42382392e-01 -4.06524003e-01  1.22552766e-02\n",
      "  2.72296786e-01  5.30596197e-01 -3.37541133e-01 -4.78776284e-02\n",
      "  2.59612203e-01  4.71693307e-01  2.81485021e-01  1.52577296e-01\n",
      "  9.92468074e-02 -1.39527231e-01 -4.11880016e-02  5.20228781e-02\n",
      "  3.23797077e-01 -2.65385002e-01 -5.11668511e-02  3.42376716e-02\n",
      " -1.43445939e-01 -5.09975076e-01  1.55710950e-01 -2.35872492e-01\n",
      " -4.35058884e-02  3.50879699e-01 -5.47972322e-01 -5.08297622e-01\n",
      " -3.16382051e-01  1.15938194e-03 -5.00386357e-01 -5.21113694e-01\n",
      "  3.75755370e-01  4.98317257e-02 -1.33607075e-01  1.78634381e+00\n",
      " -3.26684743e-01  2.85227954e-01  7.18686402e-01 -4.38250273e-01\n",
      " -1.70283616e-01 -2.76614189e-01 -1.32212818e-01 -3.22370082e-01\n",
      " -3.83464456e-01 -2.78658662e-02 -4.44754153e-01 -2.85758674e-01\n",
      "  1.71466060e-02 -3.30873191e-01  4.65811566e-02  1.69578135e-01\n",
      "  5.99636972e-01  3.47426236e-01 -3.55501056e-01  7.54839033e-02\n",
      " -4.10687596e-01  3.28010976e-01 -1.10068835e-01 -1.32470787e-01\n",
      "  5.74034095e-01 -5.71512341e-01  2.90202826e-01  1.01862609e+00\n",
      "  6.40651286e-01  2.30927199e-01  2.66996205e-01  2.24935755e-01\n",
      " -4.76751953e-01 -1.49021089e-01  8.05408508e-02  1.35307893e-01\n",
      " -2.00533628e-01  1.18563339e-01  3.99001002e-01 -2.92768598e-01\n",
      " -2.33607978e-01 -2.42962286e-01 -1.13434881e-01 -6.31409228e-01\n",
      " -4.77168232e-01  1.37608552e+00 -3.04477006e-01  6.80701854e-03\n",
      " -5.31206846e-01  3.52248132e-01 -1.87674105e-01  3.89591753e-01\n",
      "  4.52502966e-02 -2.45993212e-01  1.94721252e-01  8.00189674e-01\n",
      "  7.90387765e-02  9.53505374e-03 -2.86596328e-01  3.69423330e-01\n",
      " -4.25560325e-02 -1.92183048e-01 -2.00949043e-01  9.79481339e-01\n",
      "  2.96697080e-01 -1.23254573e+00 -3.79993856e-01  2.22383812e-01\n",
      "  3.23137254e-01 -6.07404649e-01  4.72589552e-01  3.09091777e-01\n",
      " -5.50811708e-01  3.19621503e-01  4.41805154e-01  1.14194505e-01\n",
      " -4.87645596e-01 -1.39144123e-01  4.53901261e-01  7.00237677e-02\n",
      "  4.77286786e-01 -4.70287025e-01 -6.89327002e-01  4.99394268e-01\n",
      "  1.56330749e-01 -5.49709499e-01 -1.88677475e-01 -6.90060198e-01\n",
      "  4.75550324e-01  5.82987303e-03 -2.16637596e-01  2.66476989e-01\n",
      " -3.53904784e-01  2.08953805e-02 -4.48043019e-01 -5.31971395e-01\n",
      " -3.88411283e-02 -3.79733831e-01  1.35393292e-01 -3.34814668e-01\n",
      "  3.14223558e-01  4.12584037e-01 -2.61761069e-01  3.95280331e-01\n",
      " -5.43950535e-02 -1.61435366e-01 -1.91244502e-02  8.95767063e-02\n",
      "  4.78388309e-01  2.42170349e-01 -8.53363648e-02  6.83255643e-02\n",
      "  6.71625972e-01  4.27293703e-02 -2.41716683e-01 -9.03946310e-02\n",
      " -1.37356445e-01  2.58293211e-01  5.76493442e-01  4.62749511e-01\n",
      " -1.16131343e-02 -6.08126938e-01 -3.93038869e-01 -1.94645047e+00\n",
      "  2.39377230e-01  4.13059056e-01 -2.93526441e-01  2.46926233e-01\n",
      " -7.40389884e-01  2.08985716e-01 -8.36011171e-02  2.18448430e-01\n",
      "  5.32945335e-01  4.47731823e-01 -2.82743007e-01  3.89210999e-01\n",
      "  5.63036054e-02 -4.37620953e-02  5.77857018e-01  1.54077828e-01\n",
      "  1.83482870e-01 -9.55360457e-02  1.23805135e-01  1.00321777e-01\n",
      "  1.32525042e-01  1.28932577e-02 -6.07730210e-01  2.25443035e-01\n",
      " -2.96389520e-01  2.30188584e+00  6.72613025e-01  3.76602799e-01\n",
      " -5.05816817e-01  6.14272177e-01  5.98971732e-03 -2.66410500e-01\n",
      " -1.42900789e+00  6.60268247e-01 -9.31879953e-02  2.29691610e-01\n",
      "  2.68719822e-01 -2.67337173e-01 -1.09166674e-01 -1.23028435e-01\n",
      "  1.26052946e-01 -1.43317953e-01 -9.47891295e-01 -2.08331451e-01\n",
      " -5.25782645e-01 -3.66916925e-01 -2.29024962e-01 -3.88984054e-01\n",
      "  5.34259915e-01  1.19655028e-01 -3.49709719e-01  5.15760422e-01\n",
      "  1.75840408e-01 -4.78294969e-01 -3.34120542e-01 -8.25946927e-01\n",
      "  3.32600921e-01 -5.73985457e-01  1.12896204e-01  1.80806413e-01\n",
      " -2.74245918e-01  4.36682720e-03 -6.28199935e-01  4.32769150e-01\n",
      " -4.11717109e-02  2.20929801e-01 -4.68097180e-01  9.62073952e-02\n",
      " -1.45118549e-01 -3.28893691e-01  5.72104394e-01 -4.66822922e-01\n",
      " -9.30137783e-02  5.55710971e-01  9.67602432e-02  4.62878570e-02\n",
      "  7.22669158e-03 -3.55116338e-01 -3.17167759e-01  6.87639952e-01\n",
      " -2.78592736e-01  4.22086924e-01  3.03655177e-01  5.24843931e-01\n",
      "  2.47491583e-01  4.95159000e-01  7.93321207e-02  6.70929968e-01\n",
      " -2.17289105e-01  9.52391550e-02  3.29659916e-02 -3.77907604e-01\n",
      "  3.47616412e-02  1.69545412e-01 -3.36123496e-01 -2.77338934e+00\n",
      "  3.24785590e-01 -5.46859428e-02 -1.93836130e-02  6.61715344e-02\n",
      "  2.35489458e-01  2.50874877e-01  2.25246891e-01 -1.78854123e-01\n",
      "  1.75257385e-01  2.54051208e-01  5.88983476e-01  1.96750775e-01\n",
      " -2.62854964e-01 -5.62366992e-02  3.37912738e-01  8.55532706e-01\n",
      " -4.45742905e-01  3.16888958e-01 -7.20420420e-01  2.40451440e-01\n",
      "  3.42440099e-01  1.93734574e+00 -1.86350092e-01  3.75419259e-01\n",
      " -1.92953125e-01 -3.35577801e-02 -1.77298695e-01  5.67700505e-01\n",
      " -6.26206547e-02  6.16323128e-02  4.63650636e-02  7.81068921e-01\n",
      " -1.96706951e-01  2.16230657e-02  2.37794966e-01 -1.29566476e-01\n",
      "  3.18871617e-01  3.59903276e-01 -9.10092071e-02 -1.50137916e-01\n",
      " -2.20959842e-01 -5.63868344e-01 -1.93405300e-01  3.70330989e-01\n",
      " -8.86168629e-02  3.30338001e-01 -2.99677074e-01 -7.41071030e-02\n",
      "  1.38372198e-01 -1.74606651e-01  3.38767096e-02  1.14062853e-01\n",
      " -2.06781533e-02  2.43284449e-01  1.46819353e-01  4.23557945e-02\n",
      " -2.78457105e-01 -2.98639327e-01 -6.27656132e-02 -1.86697561e-02\n",
      " -4.48014319e-01 -4.04818505e-02  4.76228535e-01  7.22635118e-03]\n",
      "\n",
      "Sentence: Sentences are passed as a list of string.\n",
      "Embedding: [-3.93862635e-01 -3.52360047e-02  2.19509304e-01 -2.07814544e-01\n",
      " -1.82300478e-01  1.97447725e-02  6.93794608e-01  3.43922019e-01\n",
      "  2.10592523e-01 -2.43807510e-01  9.12725925e-03 -2.87090242e-01\n",
      "  5.73660493e-01  1.51828632e-01 -2.12553665e-02  9.25380215e-02\n",
      " -9.50919930e-03 -2.71738172e-02 -8.06861103e-01  1.99536070e-01\n",
      "  7.10039139e-01  3.69407296e-01  1.52610056e-02 -2.38921836e-01\n",
      "  2.27182955e-01  6.45986974e-01 -9.64694917e-02 -4.02615994e-01\n",
      " -5.04841924e-01 -1.42578304e+00 -2.26190239e-01 -7.54248977e-01\n",
      "  3.14552516e-01  1.05069438e-03 -1.58944830e-01 -8.66197199e-02\n",
      " -3.19319278e-01  4.58901584e-01 -6.04273856e-01  3.81100833e-01\n",
      "  3.82963687e-01  3.55839223e-01  5.57992123e-02 -3.66868526e-01\n",
      " -2.65462667e-01 -5.72686136e-01 -4.31849748e-01 -1.45792484e-01\n",
      "  3.86427432e-01 -4.62429881e-01 -2.80395210e-01 -1.06174283e-01\n",
      "  3.00761629e-02  1.17140897e-01  1.84592232e-01  1.05639108e-01\n",
      "  3.80688220e-01  3.02562028e-01  1.60873979e-01  2.09809363e-01\n",
      "  1.41847044e-01  1.91590399e-01 -1.92381012e+00  9.10789490e-01\n",
      " -7.59850666e-02  7.17372596e-02 -1.34398296e-01 -2.66134769e-01\n",
      " -9.95723810e-03  6.83404386e-01 -4.41038944e-02  8.73201042e-02\n",
      "  1.35616302e-01  6.77331805e-01  2.11982906e-01 -2.81132340e-01\n",
      " -9.76244956e-02 -4.75875258e-01  1.40326560e-01  1.84948549e-01\n",
      "  2.01145887e-01 -3.02375495e-01 -1.27713025e-01 -1.98757514e-01\n",
      " -3.31271142e-01 -2.10801348e-01 -1.72114540e-02 -3.14732581e-01\n",
      "  1.59955412e-01  1.16150491e-01 -4.73637938e-01 -3.06395859e-01\n",
      "  3.32814790e-02  1.28075972e-01 -5.94812870e-01 -5.38974881e-01\n",
      "  2.55304545e-01  2.35481635e-01  2.77927577e-01  1.86098623e+00\n",
      " -6.22874200e-01  2.36852214e-01  4.40798253e-01 -6.05650127e-01\n",
      "  2.71148443e-01  2.54126899e-02  2.58865878e-02 -6.94639206e-01\n",
      " -3.52372050e-01 -8.91449973e-02 -3.73842925e-01 -1.32315814e-01\n",
      "  6.21243715e-01 -4.26418513e-01  2.38744870e-01  5.21678701e-02\n",
      "  5.79382300e-01  3.62239741e-02 -3.10877919e-01 -6.93723634e-02\n",
      " -2.77093172e-01  1.38488472e-01  1.90861076e-01 -8.67401659e-02\n",
      " -4.34844121e-02 -4.55433160e-01  4.19671029e-01  8.17592084e-01\n",
      "  4.23855573e-01  4.12658006e-01  5.84361136e-01 -2.73477018e-01\n",
      " -2.99523234e-01 -8.59529674e-02 -8.54554176e-02  4.32936996e-02\n",
      "  2.83115357e-01  1.79033518e-01  3.76164943e-01 -4.58685786e-01\n",
      " -3.45038772e-01 -1.14093006e+00 -2.66722083e-01 -6.97936714e-01\n",
      " -3.35548878e-01  1.32581043e+00 -3.06413889e-01  2.06428289e-01\n",
      " -6.22677684e-01  1.36586025e-01 -1.22533878e-02  2.34814897e-01\n",
      "  4.34672147e-01 -5.96832514e-01  8.08046758e-03  2.68486232e-01\n",
      "  3.47632706e-01  3.28054935e-01 -2.19390541e-01  2.49661636e-02\n",
      "  1.23883136e-01  1.11144833e-01 -3.51211518e-01  9.04265583e-01\n",
      "  2.08525136e-01 -6.53281748e-01 -1.26097962e-01  3.32494766e-01\n",
      "  1.58732012e-01 -5.52374601e-01  5.38156748e-01  1.74561068e-01\n",
      " -5.65634966e-01  1.92412078e-01  2.35231295e-01  5.94955623e-01\n",
      " -2.14915931e-01 -3.14546078e-01  4.15745676e-02  3.77354175e-02\n",
      "  2.96163023e-01 -1.39099032e-01 -5.23051798e-01  4.18562889e-01\n",
      "  2.80739605e-01 -3.89157653e-01 -4.09878910e-01 -4.47767168e-01\n",
      "  3.96111757e-01  1.31934747e-01 -4.32596684e-01  1.71006605e-01\n",
      " -4.29315001e-01 -2.06102327e-01 -6.11792266e-01 -1.84269428e-01\n",
      "  4.09945399e-01 -3.49657565e-01 -1.32813811e-01 -1.15238905e-01\n",
      "  2.61274397e-01  3.64553154e-01 -2.64316112e-01  1.68294400e-01\n",
      "  2.50363082e-01 -3.48269463e-01 -2.07519814e-01  6.83051795e-02\n",
      "  3.17614824e-01  9.42583010e-02 -2.53587216e-01  2.33532473e-01\n",
      "  5.21975756e-01  4.18916680e-02 -4.09775168e-01 -7.39687324e-01\n",
      " -1.65423572e-01  2.25157201e-01  6.10525668e-01  4.04132336e-01\n",
      "  1.50937249e-03 -8.55741501e-01 -1.81252494e-01 -1.92044401e+00\n",
      "  3.94439474e-02  5.51029801e-01 -3.65431428e-01  5.50953090e-01\n",
      " -4.65818971e-01  9.35811251e-02  3.55442008e-03  2.60323137e-01\n",
      "  3.91171724e-01  3.69053721e-01 -5.63485384e-01  8.93279389e-02\n",
      " -2.02799931e-01  1.80352330e-02  6.27710283e-01 -6.33406937e-02\n",
      " -3.01746745e-02  9.57547873e-02  2.37750903e-01 -9.03231576e-02\n",
      "  9.23253223e-02  5.93211967e-03 -4.08132195e-01  1.61559984e-01\n",
      " -1.64113149e-01  2.24788380e+00  6.57911837e-01  1.46100536e-01\n",
      " -2.76762277e-01  7.32800722e-01  2.06444442e-01  1.10376142e-02\n",
      " -1.09926498e+00  8.10583651e-01 -1.38529995e-03  2.69955713e-02\n",
      "  4.02314700e-02 -1.00958236e-01 -1.72586456e-01 -9.96780843e-02\n",
      "  4.04210776e-01 -5.41352987e-01 -5.59271574e-01  1.26827005e-02\n",
      " -5.15469313e-01 -1.51045620e-01 -4.08095717e-01 -9.81939584e-02\n",
      "  3.65255237e-01  2.48614639e-01 -5.14616251e-01  2.34157652e-01\n",
      " -1.87685981e-01  6.26789927e-02 -3.89306903e-01 -1.00676930e+00\n",
      " -1.23767525e-01 -4.36167815e-04  3.16441178e-01 -9.61128473e-02\n",
      " -1.96278960e-01  2.14915592e-02 -3.70397002e-01  2.49399811e-01\n",
      "  5.62794246e-02  2.10989371e-01 -1.54752275e-02  3.53099667e-02\n",
      " -1.81153774e-01 -1.45582423e-01  6.63625240e-01 -6.50408491e-02\n",
      " -4.44586009e-01  4.70514327e-01  1.67912781e-01 -1.97716013e-01\n",
      " -2.57171661e-01 -6.16413131e-02 -3.46919984e-01  5.14425695e-01\n",
      " -8.27539265e-02  5.51928818e-01  2.25187406e-01  4.05967027e-01\n",
      "  3.53591561e-01  4.67578590e-01  1.03848748e-01  5.75147510e-01\n",
      " -1.82150990e-01  4.05117691e-01  2.00548664e-01 -4.01501991e-02\n",
      " -4.67180461e-02  5.29295862e-01 -2.71715045e-01 -2.69636369e+00\n",
      "  3.10868114e-01  1.14459798e-01 -4.11014520e-02  7.76363770e-03\n",
      "  3.02362084e-01  2.69384295e-01 -1.18807703e-01 -2.33403161e-01\n",
      "  3.24611008e-01  3.17406535e-01  3.46121192e-01 -8.36639106e-02\n",
      " -4.20325011e-01 -3.85040930e-03  1.63154379e-01  8.32931876e-01\n",
      " -2.23364055e-01  2.91344970e-01 -3.29403102e-01  4.11460847e-01\n",
      "  2.85193980e-01  2.05272269e+00 -2.58227557e-01  4.12255585e-01\n",
      "  1.37923792e-01  1.05181206e-02 -1.06933385e-01  4.60128814e-01\n",
      " -3.63447778e-02  2.73189753e-01  4.60078754e-02  1.22907400e+00\n",
      " -4.09719437e-01  1.27898872e-01  1.15239494e-01 -3.36247951e-01\n",
      "  4.51836586e-01  4.29785073e-01 -1.99759528e-01 -5.07046998e-01\n",
      "  7.21950606e-02 -7.83221185e-01 -2.11005226e-01  8.66250932e-01\n",
      "  2.18760118e-01 -4.23785038e-02 -7.75703967e-01 -3.55802216e-02\n",
      "  1.78951979e-01 -1.86514705e-01  3.65829729e-02 -7.39539787e-02\n",
      " -2.35198721e-01  1.29321486e-01  1.80087343e-01 -2.50748992e-01\n",
      " -4.25929725e-01 -1.81733027e-01 -2.37994343e-01 -5.09618521e-02\n",
      " -8.54088426e-01 -4.04390274e-03  4.04360324e-01  2.18954563e-01]\n",
      "\n",
      "Sentence: The quick brown fox jumps over the lazy dog.\n",
      "Embedding: [-0.66294503 -0.18165357  0.3498193   0.44428396  0.13734247  0.24091722\n",
      "  0.3497237   0.43101335  0.05086902  0.03221628  0.00888732 -0.83941954\n",
      "  0.38646123  0.5360752  -0.12137885  0.11615998 -0.11115304  0.08996316\n",
      " -0.6944849   0.30520138 -0.02559811 -0.54703337 -0.41486874 -0.14206253\n",
      "  0.29313368  0.15254004 -0.212282   -0.04278411 -0.33825776 -1.4660305\n",
      "  0.3169153  -0.5954101   0.21001957 -0.5015394  -0.12533455 -0.24078219\n",
      " -0.11509343  0.43943122 -0.13226022  0.30465946  0.32082197 -0.01893254\n",
      " -0.17391948 -0.43693337 -0.06482997 -0.2079131  -0.46153247 -0.33141905\n",
      "  0.3432748  -0.3982972  -0.15839441 -0.30840188  0.32554185 -0.11309329\n",
      "  0.29812953 -0.08444729  0.527773    0.13131861  0.18545641  0.28246006\n",
      "  0.2480396   0.33386075 -1.2746115   0.8778272   0.45854828  0.1823553\n",
      " -0.35134104 -0.32486373  0.06202215  0.1580077   0.12227754  0.53265125\n",
      "  0.08232563  0.36882707  0.36991754 -0.05916193  0.04392545  0.24355225\n",
      " -0.11541092  0.03551655 -0.11477634 -0.3528137  -0.4372156  -0.03177278\n",
      " -0.04846759 -0.26355496  0.1924274  -0.6846221   0.6036356   0.654854\n",
      " -0.27518752 -0.03248648 -0.22713642  0.05893281 -0.32871208 -0.27904168\n",
      "  0.13086538 -0.0312059  -0.4113179   1.8556293  -0.5072386   0.5042749\n",
      "  0.8488535  -0.41342267  0.30758515  0.08963138 -0.0397912   0.08687992\n",
      " -0.11142982  0.05895437  0.3323365  -0.05379908  0.368423    0.0373303\n",
      "  0.24725522  0.01736096  0.06799693  0.7530009   0.06808219  0.01265011\n",
      "  0.1803245  -0.15520512  0.5260349  -0.25715065  0.11034175 -0.7913497\n",
      "  0.48793554  0.9397666   0.51951003  0.2878371   0.33385822 -0.67472845\n",
      "  0.0910869  -0.4270357   0.07055891  0.29703328 -0.09274451  0.07252092\n",
      "  0.225293   -0.44205835 -0.17506532 -1.3074374  -0.11834954 -0.85896355\n",
      " -0.19714935  0.22297086 -0.20098619  0.1248534  -0.6122188   0.21853489\n",
      " -0.02450794  0.19837809 -0.18724017 -0.16112949 -0.17088415  0.02431177\n",
      " -0.29023185  0.91321546 -0.12898837 -0.09183818 -0.25153372  0.01709848\n",
      " -0.12017733 -0.03957323  0.38756916 -0.5203663  -0.22504203  0.03100582\n",
      " -0.20495601 -0.23953523  0.14237885  0.31059083 -0.954755    0.25374833\n",
      "  0.44910404 -0.102004   -0.61804706  0.03795971 -0.01308154 -0.44523636\n",
      "  0.6835738  -0.793183   -0.63084096  0.5353396   0.37362614 -0.14830934\n",
      " -0.10710406  0.00912978  0.01998305  0.3872696  -0.22159646  0.1582581\n",
      " -0.00590749 -0.5617784  -0.624477    0.11890509 -0.36021674 -0.1291282\n",
      "  0.15269092 -0.16987926  0.49217176 -0.32663354  0.2297272   0.00380551\n",
      "  0.65355796  0.10801061  0.08244673 -0.18579029  0.2983087   0.04025754\n",
      " -0.04615847 -0.0394043   0.14731999 -0.18040168 -0.18575017  0.3731538\n",
      " -0.26565647  0.1724255   0.27900013  0.29645297  0.5489021  -0.56031007\n",
      "  0.04807255 -1.7927752   0.4733244  -0.16884804 -0.31301144  0.22613086\n",
      " -0.20656979  0.27326015 -0.6147674   0.47853604  0.5123074   0.5288678\n",
      " -0.38048482 -0.23771091 -0.08716472  0.00513925  0.9510529   0.16781199\n",
      "  0.11904605  0.15985982 -0.02918804 -0.04759064  0.01888388  0.12498624\n",
      " -0.40822962  0.5006864  -0.31758413  2.0005572   0.7199164   0.52385324\n",
      " -0.27976075  0.06007668  0.26308933 -0.71838266 -0.8657353   0.7248617\n",
      "  0.6668961   0.7021651  -0.443324   -0.26006636 -0.23307319 -0.565177\n",
      "  0.4423716   0.06381676 -0.8652089  -0.10610542 -0.02326279 -0.44280815\n",
      " -0.08960324 -0.33778957  0.12896176  0.5785158  -0.13630812  0.49756324\n",
      "  0.33848974 -0.00667143  0.04086825 -0.5138841   0.21593566 -0.18417914\n",
      "  0.11129239 -0.2334222  -0.66503066  0.2798688  -0.17055094  0.3130784\n",
      "  0.03820006 -0.12331242 -0.35835266  0.20094661  0.18014146  0.02774085\n",
      "  0.47685778  0.32672012  0.0605884   0.24155909  0.04465561  0.3545734\n",
      "  0.01759296  0.19716595 -0.15074421  0.40327093 -0.60897374  0.19711904\n",
      " -0.02927402  0.28894648 -0.7007594   0.78232163 -0.2870689   0.33017913\n",
      " -0.75762385  0.04025968  0.50464153 -0.3319324  -0.5182646  -0.23108529\n",
      " -0.02426808 -2.6251717   0.10218287  0.0368461  -0.03662364 -0.07434861\n",
      "  0.1908964   0.12959468  0.12407269 -0.50739026 -0.04405545 -0.03054486\n",
      "  0.37549904  0.3371512   0.04787726 -0.04352526  0.07651434 -0.03855422\n",
      "  0.31442997 -0.08686046 -0.580886    0.26579317 -0.07825125  1.879649\n",
      " -0.5245192   0.40386188  0.25937948 -0.16879106  0.39704558  0.65021884\n",
      " -0.37603512  0.6238921  -0.08656141  0.7291966  -0.73787874 -0.04500781\n",
      "  0.353865   -0.34764472  0.5314147   0.03512838 -0.29195836 -0.07317379\n",
      "  0.3097127   0.17497893 -0.53264624  0.742498   -0.4796381  -0.7196558\n",
      " -0.36474493 -0.11681825  0.5413811  -0.19798553 -0.27197966 -0.5201493\n",
      "  0.06405313  0.22803764  0.20033143 -0.17576277 -0.1885211  -0.51273316\n",
      " -0.41101727  0.06763787 -0.6513094   0.14099175  0.365193    1.0229417 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Our sentences to encode\n",
    "sentences = [\n",
    "    \"This framework generates embeddings for each input sentence\",\n",
    "    \"Sentences are passed as a list of string.\",\n",
    "    \"The quick brown fox jumps over the lazy dog.\"\n",
    "]\n",
    "\n",
    "# Sentences are encoded by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Print the embeddings\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A monkey is playing viola. (Score: 0.7838)\n",
      "A woman is playing violin. (Score: 0.7764)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.util import semantic_search\n",
    "\n",
    "docs = [\n",
    "    \"A man is eating food.\",\n",
    "    \"A man is eating a piece of bread.\",\n",
    "    \"The girl is carrying a baby.\",\n",
    "    \"A man is riding a horse.\",\n",
    "    \"A woman is playing violin.\",\n",
    "    \"Two men pushed carts through the woods.\",\n",
    "    \"A man is riding a white horse on an enclosed ground.\",\n",
    "    \"A monkey is playing viola.\",\n",
    "    \"A cheetah is running behind its prey.\",\n",
    "]\n",
    "\n",
    "docs_embeddings = model.encode(docs, convert_to_tensor=True)\n",
    "\n",
    "query = \"tell me about music\"\n",
    "query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "hits = semantic_search(query_embedding, docs_embeddings, top_k=2)\n",
    "hits\n",
    "\n",
    "for hit in hits[0]:\n",
    "    print(docs[hit['corpus_id']], \"(Score: %.4f)\" % hit['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def split_large_text(large_text, max_tokens):\n",
    "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokenized_text = enc.encode(large_text)\n",
    "\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    for token in tokenized_text:\n",
    "        current_chunk.append(token)\n",
    "        current_length += 1\n",
    "\n",
    "        if current_length >= max_tokens:\n",
    "            chunks.append(enc.decode(current_chunk).rstrip(' .,;'))\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(enc.decode(current_chunk).rstrip(' .,;'))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why use tokens?\n",
    "\n",
    "> By breaking words into smaller parts (tokens), LLMs can better handle new or unusual words by understanding their building blocks. It also helps the model grasp the nuances of language, such as different word forms and contextual meanings.\n",
    "\n",
    "[source](https://kelvin.legal/understanding-large-language-models-words-versus-tokens/#:~:text=By%20breaking%20words%20into%20smaller,word%20forms%20and%20contextual%20meanings.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "22\n",
      "[b'If', b' we', b' split', b' a', b' text', b' by', b' number', b' of', b' characters', b',', b' it', b' is', b' not', b' obvious', b' how', b' many', b' tokens', b' these', b' chunks', b' will', b' be', b'.']\n",
      "22\n",
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'If we split a text by number of characters, it is not obvious how many tokens these chunks will be.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "sent = \"If we split a text by number of characters, it is not obvious how many tokens these chunks will be.\"\n",
    "\n",
    "print(len(sent.split()))\n",
    "\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "encoded = enc.encode(sent)\n",
    "\n",
    "print(len(encoded))\n",
    "tokens = [enc.decode_single_token_bytes(x) for x in encoded]\n",
    "print(tokens)\n",
    "print(len(tokens))\n",
    "\n",
    "\n",
    "decoded = enc.decode(encoded)\n",
    "print(len(decoded.split()))\n",
    "decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['If we split a text by number of characters',\n",
       " ' it is not obvious how many tokens these chunks will',\n",
       " ' be.\\nAnd at the same time if we want',\n",
       " ' to split a text into bigger possible chunks and keep',\n",
       " ' these chunks under certain LLM tokens limit, we',\n",
       " ' cannot operate by number of characters']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = \"\"\"If we split a text by number of characters, it is not obvious how many tokens these chunks will be.\n",
    "And at the same time if we want to split a text into bigger possible chunks and keep these chunks under certain LLM tokens limit, we cannot operate by number of characters.\"\"\"\n",
    "split_large_text(doc, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
